* 使用spark-submit运行包出现找不到类的情况
```shell
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/module/spark-yarn/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/module/hadoop-3.1.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
2023-03-28 15:55:17,333 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Error: Failed to load class com/spark/show/sgiw.scala.
2023-03-28 15:55:17,431 INFO util.ShutdownHookManager: Shutdown hook called
2023-03-28 15:55:17,432 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-d7d65253-c938-4429-8d1f-abad3d71e1af
```

* spark和scala需要拷贝hive-site.xml吗???
* 需要创建hive分区表(就是在hive创建一个和mysql相似表结构)
* 将ods库全量抽取到dwd需要创建表吗

 //获取前一天的时间 当然也可以手动指定
    val lo_time=LocalDate.now().plusDays(-1).toString().replace("-","")
 
    //添加一个分区字段,值为前面获取的时间
    val frame = df_mysql.withColumn("data", lit(lo_time))
  
  就是在数据库文件下有null值怎么剔除