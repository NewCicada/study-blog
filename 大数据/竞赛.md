- 查看数据集的前五条数据
```shell
head -5 user_log.csv
```

- 删除文件第一行记录，即字段名称
```shell
ssh -i '1d' user_log.csv
```
* 再看一遍
```shell
head -5 user_log.csv
```

- 启动hadoop
* 进入hadoop下的sbin目录
```shell
start-dfs.sh
```

* 查看当前运行进程
```shell
jps
```
* 如果出现下面这些进程，说明Hadoop启动成功了。
```shell
3765 NodeManager
3639 ResourceManager
3800 Jps
3261 DataNode
3134 NameNode
3471 SecondaryNameNode
```

- 启动Mysql
```shell
service mysql start # 可以在如何目录下执行此命令
```
> 由于Hive是基于Hadoop的数据仓库，使用HiveQL语言撰写的查询语句，最终都会被Hive自动解析成MapReduce任务由Hadoop去具体执行，因此，需要启动Hadoop，然后再启动Hive。由于前面我们已经启动了Hadoop，所以，这里不需要再次启动Hadoop。下面，在这个新的终端中执行下面命令进入Hive：
* 进入hive目录
```shell
cd /usr/local/hive
```
* 启动成功会出现一个`hive>`命令提示符状态,
* 在Hive中创建一个数据库`obs`
```hive
create database dbtaobao;
use dbtaobao;
```

* 在`obs`中创建一个表
```hive
CREATE EXTERNAL TABLE dbtaobao.user_log(user_id INT,item_id INT,cat_id INT,merchant_id INT,brand_id INT,month STRING,day STRING,action INT,age_range INT,gender INT,province STRING) COMMENT 'Welcome to xmu dblab,Now create dbtaobao.user_log!' ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE LOCATION '/dbtaobao/dataset/user_log';
```
* 导入成功
* 查询
```hive
select * from user_log limit 10;
```
- 需要启动hadoop、hive、mysql
```hive
hive> use dbtaobao; -- 使用dbtaobao数据库
hive> show tables; -- 显示数据库中所有表。
hive> show create table user_log; -- 查看user_log表的各种属性；
```
* 查看表的简单结构
```hive
desc user_log;
```

## Docker命令
```docker
// 进入节点
docker exec -it master/bin/bash
```
### 常用命令
* docker pull 镜像名<:tags> - 从远程仓库抽取镜像
* docker images - 查看本地下载的镜像
* docker run 镜像名<:tags> - 创建容器，启动应用
* docker ps - 查看正在运行的镜像
* docker rm <-f> 容器id - 删除容器
* docker rmi <-f> 镜像名：<:tags> - 删除镜像

## 查看分区情况
```hive
show partitions ods.customer_inf;
```
* 该命令将显示所有已经存在的分区及其对应的值。如果之前没有创建过该分区，则会显示一个分区，即当前日期的前一天日期。